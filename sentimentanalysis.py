# -*- coding: utf-8 -*-
"""SentimentAnalysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IVK3q4NQCsQZbaK7_1EZrk20tFlnXVgN
"""

import re
import warnings 
import nltk
from nltk.tokenize import TweetTokenizer 
from nltk.stem.snowball import SnowballStemmer 
import pandas as pd
import nltk
from nltk.tokenize import TweetTokenizer 
from nltk.stem.snowball import SnowballStemmer

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
warnings.filterwarnings("ignore")

tweets_data = pd.read_csv("https://raw.githubusercontent.com/CankayaUniversity/ceng-407-408-2020-2021-Sentiment-Analysis-of-the-Feedback-form-Airplane-Passengers/main/Tweets.csv") 
 
tweets_data

df=tweets_data.iloc[:,[10,1,12]]  

df.columns = ['text', 'sentiment','datetime'] 
data= df
data

import nltk
nltk.download('punkt')
data['text']=data['text'].str.replace("(@[A-Za-z0-9]+)|([^0-9A-Za-z \t])|(\w+:\/\/\S+)|([0-9])","")
data['text']=data['text'].apply(nltk.word_tokenize)
data

stemmer = SnowballStemmer('english')
data['text']=data['text'].apply(lambda x: [stemmer.stem(y) for y in x])
data

import nltk
nltk.download('stopwords')
stopwords = nltk.corpus.stopwords.words('english')
data['text']=data['text'].apply(lambda x: [y for y in x if y not in stopwords])
data

data['text'] = data['text'].str.join(" ")
data

print ("data shape = ", data.shape)

sentiment = sorted(data['sentiment'].unique())
sentiment_mapping = dict(zip(sentiment, range(0, len(sentiment) + 1)))
data['sentiment']  = data['sentiment'].map(sentiment_mapping).astype(int)
data

X = data['text']
y = data['sentiment']

import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import itertools
import collections

import tweepy as tw
import nltk
from nltk.corpus import stopwords
import re
import networkx
from textblob import TextBlob

sentiment_objects = [TextBlob(tweets_data) for tweets_data in tweets_data['text']]

sentiment_objects[0].polarity, sentiment_objects[0]

sentiment_values = [[tweets_data.sentiment.polarity, str(tweets_data)] for tweets_data in sentiment_objects]

sentiment_values[0]

sentiment_df = pd.DataFrame(sentiment_values, columns=["polarity", "tweets"])

sentiment_df.head()

fig, ax = plt.subplots(figsize=(8, 6))

sentiment_df.hist(bins=[-1, -0.75, -0.5, -0.25, 0.25, 0.5, 0.75, 1],
             ax=ax,
             color="purple")

plt.title("Sentiments from Tweets on Climate Change")
plt.show()

sentiment_df = sentiment_df[sentiment_df.polarity != 0]

sentiment_df.head()

fig, ax = plt.subplots(figsize=(8, 6))

sentiment_df.hist(bins=[-1, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1],
             ax=ax,
             color="purple")

plt.title("Sentiments from Tweets on Climate Change")
plt.show()

import numpy as np
from scipy.sparse import hstack
from sklearn.feature_extraction.text import CountVectorizer
cntVectorizer = CountVectorizer(ngram_range=(1,2))

VectorizedData = cntVectorizer.fit_transform(tweets_data.text)

IndexedData = hstack((np.array(range(0,VectorizedData.shape[0]))[:,None], VectorizedData))

def sentiment(emotion):
    return {
        'negative': 0,
        'neutral': 1,
        'positive' : 2
    }[emotion]
    
targets = tweets_data.airline_sentiment.apply(sentiment)

from sklearn.model_selection import train_test_split
data_train, data_test, targets_train, targets_test = train_test_split(IndexedData, targets, test_size=0.2, random_state=0)

data_train_index = data_train[:,0] 
data_train = data_train[:,1:] 
data_test_index = data_test[:,0]
data_test = data_test[:,1:]

from sklearn.svm import SVC  


model = SVC()  
model.fit(data_train, targets_train)
predictions = model.predict(data_test)

from sklearn.metrics import accuracy_score

acc_score = accuracy_score(targets_test, predictions)  
acc_score

from sklearn import svm
from sklearn.multiclass import OneVsRestClassifier
clf = OneVsRestClassifier(svm.SVC())
 
clf_output = clf.fit(data_train, targets_train)

clf.score(data_test, targets_test)